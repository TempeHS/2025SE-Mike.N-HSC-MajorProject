{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f35f541",
   "metadata": {},
   "source": [
    "**Sprint 2: Data Wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04266fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site_dic.pkl', 'sample_submission.csv', 'test_sessions.csv', 'train_sessions.csv']\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ba629",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868e673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('../data')\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions.csv'), index_col='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af8f10",
   "metadata": {},
   "source": [
    "**Basic Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9523dd4b",
   "metadata": {},
   "source": [
    "Convert timestamps into pd.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4429839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list columns for easy access\n",
    "sites_cols = ['site%s' % i for i in range(1, 11)]\n",
    "times_cols = ['time%s' % i for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ded2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert timestamps to pd.datetime\n",
    "train_df[times_cols] = train_df[times_cols].apply(pd.to_datetime)\n",
    "test_df[times_cols] = test_df[times_cols].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03426aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(by = 'time1')\n",
    "test_df = test_df.sort_values(by = 'time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297f7fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "session_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time1",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time2",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time3",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time4",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time5",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time6",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time7",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time8",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time9",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "site10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time10",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "01647660-d39e-4a13-9801-a64fd880005d",
       "rows": [
        [
         "65540",
         "21",
         "2014-05-01 17:14:03",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "64199",
         "23",
         "2014-05-02 07:52:08",
         "66.0",
         "2014-05-02 07:54:08",
         "63.0",
         "2014-05-02 07:54:08",
         "2626.0",
         "2014-05-02 07:55:09",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2268",
         "979",
         "2014-05-02 07:57:51",
         "73.0",
         "2014-05-02 07:59:34",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29734",
         "66",
         "2014-05-02 08:05:16",
         "69.0",
         "2014-05-02 08:05:17",
         "67.0",
         "2014-05-02 08:05:17",
         "70.0",
         "2014-05-02 08:05:17",
         "71.0",
         "2014-05-02 08:05:17",
         "68.0",
         "2014-05-02 08:05:17",
         "71.0",
         "2014-05-02 08:05:18",
         "70.0",
         "2014-05-02 08:05:18",
         "69.0",
         "2014-05-02 08:05:18",
         "67.0",
         "2014-05-02 08:05:18"
        ],
        [
         "77048",
         "167",
         "2014-05-02 08:05:32",
         "167.0",
         "2014-05-02 08:05:33",
         "359.0",
         "2014-05-02 08:05:34",
         "167.0",
         "2014-05-02 08:05:34",
         "167.0",
         "2014-05-02 08:05:35",
         "305.0",
         "2014-05-02 08:09:19",
         "306.0",
         "2014-05-02 08:09:20",
         "306.0",
         "2014-05-02 08:09:22",
         "979.0",
         "2014-05-02 08:09:54",
         "68.0",
         "2014-05-02 08:12:46"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65540</th>\n",
       "      <td>21</td>\n",
       "      <td>2014-05-01 17:14:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64199</th>\n",
       "      <td>23</td>\n",
       "      <td>2014-05-02 07:52:08</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2014-05-02 07:54:08</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-05-02 07:54:08</td>\n",
       "      <td>2626.0</td>\n",
       "      <td>2014-05-02 07:55:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>979</td>\n",
       "      <td>2014-05-02 07:57:51</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2014-05-02 07:59:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29734</th>\n",
       "      <td>66</td>\n",
       "      <td>2014-05-02 08:05:16</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77048</th>\n",
       "      <td>167</td>\n",
       "      <td>2014-05-02 08:05:32</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2014-05-02 08:05:33</td>\n",
       "      <td>359.0</td>\n",
       "      <td>2014-05-02 08:05:34</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2014-05-02 08:05:34</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2014-05-02 08:05:35</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2014-05-02 08:09:19</td>\n",
       "      <td>306.0</td>\n",
       "      <td>2014-05-02 08:09:20</td>\n",
       "      <td>306.0</td>\n",
       "      <td>2014-05-02 08:09:22</td>\n",
       "      <td>979.0</td>\n",
       "      <td>2014-05-02 08:09:54</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2014-05-02 08:12:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "65540          21 2014-05-01 17:14:03    NaN                 NaT    NaN   \n",
       "64199          23 2014-05-02 07:52:08   66.0 2014-05-02 07:54:08   63.0   \n",
       "2268          979 2014-05-02 07:57:51   73.0 2014-05-02 07:59:34    NaN   \n",
       "29734          66 2014-05-02 08:05:16   69.0 2014-05-02 08:05:17   67.0   \n",
       "77048         167 2014-05-02 08:05:32  167.0 2014-05-02 08:05:33  359.0   \n",
       "\n",
       "                         time3   site4               time4  site5  \\\n",
       "session_id                                                          \n",
       "65540                      NaT     NaN                 NaT    NaN   \n",
       "64199      2014-05-02 07:54:08  2626.0 2014-05-02 07:55:09    NaN   \n",
       "2268                       NaT     NaN                 NaT    NaN   \n",
       "29734      2014-05-02 08:05:17    70.0 2014-05-02 08:05:17   71.0   \n",
       "77048      2014-05-02 08:05:34   167.0 2014-05-02 08:05:34  167.0   \n",
       "\n",
       "                         time5  site6               time6  site7  \\\n",
       "session_id                                                         \n",
       "65540                      NaT    NaN                 NaT    NaN   \n",
       "64199                      NaT    NaN                 NaT    NaN   \n",
       "2268                       NaT    NaN                 NaT    NaN   \n",
       "29734      2014-05-02 08:05:17   68.0 2014-05-02 08:05:17   71.0   \n",
       "77048      2014-05-02 08:05:35  305.0 2014-05-02 08:09:19  306.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "65540                      NaT    NaN                 NaT    NaN   \n",
       "64199                      NaT    NaN                 NaT    NaN   \n",
       "2268                       NaT    NaN                 NaT    NaN   \n",
       "29734      2014-05-02 08:05:18   70.0 2014-05-02 08:05:18   69.0   \n",
       "77048      2014-05-02 08:09:20  306.0 2014-05-02 08:09:22  979.0   \n",
       "\n",
       "                         time9  site10              time10  \n",
       "session_id                                                  \n",
       "65540                      NaT     NaN                 NaT  \n",
       "64199                      NaT     NaN                 NaT  \n",
       "2268                       NaT     NaN                 NaT  \n",
       "29734      2014-05-02 08:05:18    67.0 2014-05-02 08:05:18  \n",
       "77048      2014-05-02 08:09:54    68.0 2014-05-02 08:12:46  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fff17c",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b16646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that fills NaN values in the site columns with zeros and converts them to integers.\n",
    "    This prepares the site columns for further processing or vectorization.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        sites = ['site%s' % i for i in range(1, 11)]\n",
    "        return X[sites].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb4731",
   "metadata": {},
   "source": [
    "We combine the site id to a single string for the CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc9dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListPreparator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that converts each row of site IDs into a whitespace-separated string.\n",
    "    This format is suitable for use with CountVectorizer.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.values.tolist()\n",
    "        return [\" \".join([str(site) for site in row]) for row in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea870365",
   "metadata": {},
   "source": [
    "Some features explored in the EDA showed significant differences between Alice and Intruder. Let's put them into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3744a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that adds time-based and categorical features:\n",
    "    - Morning, day, evening indicators based on hour\n",
    "    - Summer indicator based on month\n",
    "    - Weekday and year as numeric features\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X, y=None):\n",
    "        hour = X['time1'].apply(lambda ts: ts.hour)\n",
    "        morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "        day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "        evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "        month = X['time1'].apply(lambda ts: ts.month)\n",
    "        summer = ((month >= 6) & (month <= 8)).astype('int')\n",
    "        weekday = X['time1'].apply(lambda ts: ts.weekday()).astype('int')\n",
    "        year = X['time1'].apply(lambda ts: ts.year).astype('int')\n",
    "        X = np.c_[morning.values, day.values, evening.values, summer.values, weekday.values, year.values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e71cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that adds session duration as a feature, normalized using a power transform.\n",
    "    The duration is calculated as the difference between the max and min timestamps in a session.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        times = ['time%s' % i for i in range(1, 11)]\n",
    "        session_duration = (X[times].max(axis=1) - X[times].min(axis=1)).astype('timedelta64[ms]').astype(int) ** 0.2\n",
    "        X = np.c_[session_duration.values]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d75787",
   "metadata": {},
   "source": [
    "We make 2 pipelines:\n",
    "* vectorizer_pipeline: prepares the dataset for tokenizer by imputing NaNs in siteID columns, and combining them into a list of strings. CountVectorizer() converts a collection of text into a matrix of token counts. ngram_range of (1,3) means that the vectorizer will extract unigrams (single site IDs), bigrams (pairs of site IDs) and trigrams (triplets of site IDs). Only the 10000 most frequent n-grams are kept as features. Returns a a 2D-array of these features.\\\n",
    "For example, given array = ['00' , '01', '00', '02'], the CountVectorizer will return a matrix that counts up the frequency of each element (token): \\\n",
    "[['00', '01', '02'], \\\n",
    "[2, 1, 1]] \n",
    "* feature_pipeline: Returns a 2D-array of engineered features from the given dataset.\n",
    "* scaled_pipeline: Returns a 2D-array of engineered features (with scaling) from the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "451827b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the pipelines\n",
    "vectorizer_pipeline = Pipeline([\n",
    "    ('data_prep', DataPreparator()),\n",
    "    ('tokenizer_prep', ListPreparator()),\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,3), max_features=60000))\n",
    "])\n",
    "feature_pipeline = Pipeline([('feature_engineering', AttributesAdder())])\n",
    "\n",
    "scaled_pipeline = Pipeline([\n",
    "    ('scaled_feature_adder', ScaledAttributesAdder()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b834a",
   "metadata": {},
   "source": [
    "FeatureUnion performs the transformation processes in parallel, concatenating them together at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7df13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('vectorizer_pipeline', vectorizer_pipeline),\n",
    "    ('feature_pipeline', feature_pipeline),\n",
    "    ('scaled_pipeline', scaled_pipeline)\n",
    "])\n",
    "\n",
    "no_vectorizer_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('feature_pipeline', feature_pipeline),\n",
    "    ('scaled_pipeline', scaled_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dfb85f",
   "metadata": {},
   "source": [
    "Apply the all preprocessing processes to the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7df13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_pipeline.fit_transform(train_df)\n",
    "X_test = full_pipeline.transform(test_df)\n",
    "\n",
    "y_train = train_df[\"target\"].astype('int').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067dfda3",
   "metadata": {},
   "source": [
    "We will make a pipeline without the vectorizer to analyse the other transformation processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be475ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same features as in the pipeline (AttributesAdder + ScaledAttributesAdder)\n",
    "# These are: morning, day, evening, summer, weekday, year, session_duration\n",
    "\n",
    "feature_columns = [\n",
    "    \"morning\", \"day\", \"evening\", \"summer\", \"weekday\", \"year\"\n",
    "]\n",
    "scaled_columns = [\n",
    "    \"session_duration\"\n",
    "]\n",
    "\n",
    "X_train_no_vectorizer = no_vectorizer_pipeline.fit_transform(train_df)\n",
    "X_test_no_vectorizer = no_vectorizer_pipeline.transform(test_df)\n",
    "\n",
    "X_train_no_tokenizer_df = pd.DataFrame(\n",
    "    X_train_no_vectorizer, \n",
    "    columns=feature_columns + scaled_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b88d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "morning",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "evening",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "summer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weekday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "session_duration",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "617f3614-d336-4a2b-8d49-35d0e73241f9",
       "rows": [
        [
         "count",
         "253561.0",
         "253561.0",
         "253561.0",
         "253561.0",
         "253561.0",
         "253561.0",
         "253561.0"
        ],
        [
         "mean",
         "0.48085076174963814",
         "0.4905525692042546",
         "0.028596669046107248",
         "0.009950268377234669",
         "2.2897409301903684",
         "2013.705494930214",
         "1.145562095033262e-16"
        ],
        [
         "std",
         "0.49963415734733524",
         "0.49991172386661115",
         "0.16667036065570331",
         "0.0992537122139433",
         "1.6104674695342105",
         "0.45582085634066905",
         "1.000001971917917"
        ],
        [
         "min",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2013.0",
         "-2.379875516659317"
        ],
        [
         "25%",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "2013.0",
         "-0.6786939481781287"
        ],
        [
         "50%",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.0",
         "2014.0",
         "-0.15142079953781826"
        ],
        [
         "75%",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "4.0",
         "2014.0",
         "0.5873239986626915"
        ],
        [
         "max",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "6.0",
         "2014.0",
         "2.781738935498302"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morning</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>summer</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>session_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>253561.000000</td>\n",
       "      <td>253561.000000</td>\n",
       "      <td>253561.000000</td>\n",
       "      <td>253561.000000</td>\n",
       "      <td>253561.000000</td>\n",
       "      <td>253561.000000</td>\n",
       "      <td>2.535610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.480851</td>\n",
       "      <td>0.490553</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>2.289741</td>\n",
       "      <td>2013.705495</td>\n",
       "      <td>1.145562e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499634</td>\n",
       "      <td>0.499912</td>\n",
       "      <td>0.166670</td>\n",
       "      <td>0.099254</td>\n",
       "      <td>1.610467</td>\n",
       "      <td>0.455821</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>-2.379876e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>-6.786939e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>-1.514208e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.873240e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>2.781739e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             morning            day        evening         summer  \\\n",
       "count  253561.000000  253561.000000  253561.000000  253561.000000   \n",
       "mean        0.480851       0.490553       0.028597       0.009950   \n",
       "std         0.499634       0.499912       0.166670       0.099254   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             weekday           year  session_duration  \n",
       "count  253561.000000  253561.000000      2.535610e+05  \n",
       "mean        2.289741    2013.705495      1.145562e-16  \n",
       "std         1.610467       0.455821      1.000002e+00  \n",
       "min         0.000000    2013.000000     -2.379876e+00  \n",
       "25%         1.000000    2013.000000     -6.786939e-01  \n",
       "50%         2.000000    2014.000000     -1.514208e-01  \n",
       "75%         4.000000    2014.000000      5.873240e-01  \n",
       "max         6.000000    2014.000000      2.781739e+00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the features were added correctly\n",
    "X_train_no_tokenizer_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268b3ac",
   "metadata": {},
   "source": [
    "The ranges of features are within the expected values. Tranformation processes were applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855b3f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in sample: 0\n",
      "Infs in sample: 0\n",
      "Sample rows:\n",
      " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.00000000e+00\n",
      "   2.01300000e+03 -2.37987552e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.00000000e+00\n",
      "   2.01300000e+03  2.77368466e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.00000000e+00\n",
      "   2.01300000e+03 -8.58827028e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.00000000e+00\n",
      "   2.01300000e+03 -9.43872634e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.00000000e+00\n",
      "   2.01300000e+03 -1.05572590e+00]]\n",
      "Nonzero elements: 4423441\n",
      "Sparsity: 0.03%\n",
      "Sample min: -2.379875516659317\n",
      "Sample max: 2013.0\n"
     ]
    }
   ],
   "source": [
    "# The transformed dataset is very large. We sample a few rows to take a look.\n",
    "sample = X_train[:5].toarray()\n",
    "print(\"NaNs in sample:\", np.isnan(sample).sum())\n",
    "print(\"Infs in sample:\", np.isinf(sample).sum())\n",
    "print(\"Sample rows:\\n\", sample)\n",
    "\n",
    "# Check sparsity\n",
    "print(\"Nonzero elements:\", X_train.nnz)\n",
    "print(\"Sparsity: {:.2f}%\".format(100 * X_train.nnz / (X_train.shape[0] * X_train.shape[1])))\n",
    "\n",
    "# Check min/max (Make sure everything is scaled)\n",
    "print(\"Sample min:\", sample.min())\n",
    "print(\"Sample max:\", sample.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4112056",
   "metadata": {},
   "source": [
    "The dataset looks good, without NaNs, infs or large outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3e1d9",
   "metadata": {},
   "source": [
    "We extract the transformed dataset into new files. The transformed dataset is very sparse, and therefore must be stored in .npz files, which are more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54009f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "sparse.save_npz('../data/X_train_sparse.npz', X_train)\n",
    "sparse.save_npz('../data/X_test_sparse.npz', X_test)\n",
    "np.save('../data/y_train.npy', y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
